diff --cc modules/render_modules.py
index 8c24b96,85968ca..0000000
--- a/modules/render_modules.py
+++ b/modules/render_modules.py
@@@ -393,11 -505,137 +505,137 @@@ class RandHydraMLPDiffuse(torch.nn.Modu
          diffuse, tint, extra = self(*args, **kwargs)
          diffuse_v = inv_sigmoid(diffuse).mean().detach().item()
          # tint_v = (tint / (1-tint)).log()
-         v = (0.25 if not conserve_energy else 0.5)/float(mean_brightness)
 -        v = 0.25 if not conserve_energy else 0.25 / float(mean_brightness)
++        v = (0.25 if not conserve_energy else 0.5) / float(mean_brightness)
          self.diffuse_bias += inv_sigmoid(v) - diffuse_v
 -        ic(diffuse_v, self.diffuse_bias)
 +        ic(self.diffuse_bias, mean_brightness, v)
  
-         roughness = (extra['r1'] + extra['r2']) / 2 / 2
+         roughness = (extra["r1"] + extra["r2"]) / 2 / 2
+         roughness_v = inv_sigmoid(roughness).mean().detach().item()
+         self.roughness_bias += inv_sigmoid(self.start_roughness) - roughness_v
+ 
+         # self.tint_bias += 1.1 - diffuse_v
+ 
 -    def forward(self, pts, viewdirs, features, std, **kwargs):
++    def forward(self, pts, viewdirs, features, std=0, **kwargs):
+         if self.allocation > 0:
+             features = features[..., : self.allocation]
+         device = features.device
+         B = pts.shape[0]
+         size = pts[..., 3:4].expand(pts[..., :3].shape)
+         pts = pts[..., :3]
+         indata = []
+         if self.pospe >= 0:
+             indata.append(pts)
+         if self.pospe > 0:
+             indata += [safemath.integrated_pos_enc((pts, size), 0, self.pospe)]
+ 
+         if self.feape >= 0:
+             indata.append(features)
+         if self.feape > 0:
+             indata += [positional_encoding(features, self.feape)]
+         if self.view_encoder is not None:
+             indata += [
+                 self.view_encoder(
+                     viewdirs, torch.tensor(1e-3, device=device).expand(B)
+                 ).reshape(B, -1),
+                 viewdirs,
+             ]
+         mlp_in = torch.cat(indata, dim=-1)
+ 
+         if self.roughness_view_encoder is not None:
+             indata += [
+                 self.roughness_view_encoder(
+                     viewdirs, torch.tensor(1e-3, device=device).expand(B)
+                 ).reshape(B, -1),
+                 viewdirs,
+             ]
+         rough_mlp_in = torch.cat(indata, dim=-1)
+         diffuse = torch.sigmoid(
+             self.diffuse_mul * self.diffuse_mlp(mlp_in) + self.diffuse_bias
+         )
+         diffuse = (diffuse + torch.randn_like(diffuse) * std).clip(min=0, max=1)
+         r = torch.sigmoid(self.roughness_mlp(rough_mlp_in) + self.roughness_bias) / 2
 -        r = (r + torch.randn_like(r) * std).clip(min=1e-4, max=1)
++        r = (r + torch.randn_like(r) * std).clip(min=1e-2, max=1)
+         tint = torch.sigmoid(self.tint_mlp(mlp_in) + self.tint_bias)
+         tint = (tint + torch.randn_like(tint) * std).clip(min=0, max=1)
+ 
+         # ic(f0)
+         return (
+             diffuse,
+             tint,
+             dict(
+                 diffuse=diffuse,
+                 r1=r[:, 0:1],
+                 r2=r[:, 1:2],
+                 f0=tint,
+                 tint=tint,
+             ),
+         )
+ 
+ 
+ class HydraMLPDiffuse(torch.nn.Module):
+     in_channels: int
+     viewpe: int
+     feape: int
+     refpe: int
+     featureC: int
+     num_layers: int
+ 
+     def __init__(
+         self,
+         in_channels,
+         pospe=12,
+         view_encoder=None,
+         roughness_view_encoder=None,
+         roughness_cfg=None,
+         feape=6,
+         allocation=0,
+         unlit_tint=False,
+         lr=1e-4,
+         tint_bias=-1,
+         diffuse_bias=-2,
+         diffuse_mul=1,
+         roughness_bias=1,
+         start_roughness=0.35,
+         **kwargs,
+     ):
+         super().__init__()
+ 
+         in_channels = in_channels if allocation <= 0 else allocation
+         self.in_mlpC = (
+             +2 * max(feape, 0) * in_channels + in_channels if feape >= 0 else 0
+         )
+         if pospe >= 0:
+             self.in_mlpC += 2 * pospe * 3 + 3
+         self.unlit_tint = unlit_tint
+         self.tint_bias = tint_bias
+         self.diffuse_bias = diffuse_bias
+         self.roughness_bias = roughness_bias
+         self.lr = lr
+         self.allocation = allocation
+         self.diffuse_mul = diffuse_mul
+         self.start_roughness = start_roughness
+ 
+         self.view_encoder = view_encoder
+         self.roughness_view_encoder = roughness_view_encoder
+         self.in_mlpC += get_dim(self.view_encoder, 3)
+         self.feape = feape
+         self.pospe = pospe
+         self.diffuse_mlp = util.create_mlp(self.in_mlpC, 3, **kwargs)
+         self.tint_mlp = util.create_mlp(self.in_mlpC, 3, **kwargs)
+         roughness_cfg = roughness_cfg if roughness_cfg is not None else kwargs
+         self.roughness_mlp = util.create_mlp(
+             self.in_mlpC + get_dim(self.roughness_view_encoder, 3), 2, **roughness_cfg
+         )
+ 
+     def calibrate(self, mean_brightness, conserve_energy, *args, **kwargs):
+         diffuse, tint, extra = self(*args, **kwargs)
+         diffuse_v = inv_sigmoid(diffuse).mean().detach().item()
+         # tint_v = (tint / (1-tint)).log()
 -        v = 0.25 if not conserve_energy else 0.25 / float(mean_brightness)
++        v = (0.25 if not conserve_energy else 0.5) / float(mean_brightness)
+         self.diffuse_bias += inv_sigmoid(v) - diffuse_v
+         ic(diffuse_v, self.diffuse_bias)
+ 
+         roughness = (extra["r1"] + extra["r2"]) / 2 / 2
          roughness_v = inv_sigmoid(roughness).mean().detach().item()
          self.roughness_bias += inv_sigmoid(self.start_roughness) - roughness_v
  
diff --git a/configs/model/microfacet_tensorf.yaml b/configs/model/microfacet_tensorf.yaml
index fd2a37f..8f05fc0 100644
--- a/configs/model/microfacet_tensorf.yaml
+++ b/configs/model/microfacet_tensorf.yaml
@@ -63,6 +63,8 @@ arch:
     target_num_samples: [800000]
     russian_roulette: False
     max_retrace_rays: [10000]
+    start_std: 0.0
+    std_decay: 1.0
     cold_start_bg_iters: 0
     detach_N_iters: 0
     anoise: 0.25
@@ -103,7 +105,7 @@ arch:
 
     diffuse_module:
       _partial_: True
-      _target_: modules.render_modules.HydraMLPDiffuse
+      _target_: modules.render_modules.RandHydraMLPDiffuse
       pospe: -1
       feape: 0
       # pospe: 12
diff --git a/models/microfacet.py b/models/microfacet.py
index cabfc80..7021021 100644
--- a/models/microfacet.py
+++ b/models/microfacet.py
@@ -23,6 +23,9 @@ class Microfacet(torch.nn.Module):
         percent_bright,
         cold_start_bg_iters,
         detach_N_iters,
+        start_std=0,
+        std_decay=1,
+        std_decay_interval=10,
         conserve_energy=True,
         no_emitters=True,
         visibility_module=None,
@@ -43,6 +46,10 @@ class Microfacet(torch.nn.Module):
         self.brdf.init_val = 0.5 if self.conserve_energy else 0.25
         self.no_emitters = no_emitters
 
+        self.std = start_std
+        self.std_decay = std_decay
+        self.std_decay_interval = std_decay_interval
+
         self.anoise = anoise
         self.russian_roulette = russian_roulette
         self.target_num_samples = target_num_samples
@@ -97,6 +104,8 @@ class Microfacet(torch.nn.Module):
             self.detach_bg = False
         if iter > batch_mul * self.detach_N_iters:
             self.detach_N = False
+        if iter % self.std_decay_interval == 0:
+            self.std *= self.std_decay
         return False
 
     @torch.no_grad()
@@ -125,7 +134,9 @@ class Microfacet(torch.nn.Module):
         assert xyzs.shape[0] == viewdirs.shape[0]
         assert xyzs.shape[0] == app_features.shape[0]
 
-        diffuse, tint, matprop = self.diffuse_module(xyzs, viewdirs, app_features)
+        diffuse, tint, matprop = self.diffuse_module(
+            xyzs, viewdirs, app_features, std=0
+        )
 
         n_angs = ang_vecs.shape[-2]
         n_views = viewdirs.shape[0]
@@ -267,18 +278,24 @@ class Microfacet(torch.nn.Module):
         device = xyzs.device
 
         noise_app_features = app_features + torch.randn_like(app_features) * self.anoise
-        albedo, tint, matprop = self.diffuse_module(xyzs_normed, viewdirs, app_features)
+        std = self.std if is_train else 0
+        albedo, tint, matprop = self.diffuse_module(
+            xyzs_normed, viewdirs, app_features, std=std
+        )
 
         # compute spherical harmonic coefficients for the background
         if self.no_emitters:
             with torch.no_grad():
                 coeffs, conv_coeffs = bg_module.get_spherical_harmonics(100)
-            evaled = sh.eval_sh_bases(conv_coeffs.shape[0], normals)
-            E = (
-                (conv_coeffs.reshape(1, -1, 3) * evaled.reshape(evaled.shape[0], -1, 1))
-                .sum(dim=1)
-                .detach()
-            )
+                evaled = sh.eval_sh_bases(conv_coeffs.shape[0], normals)
+                E = (
+                    (
+                        conv_coeffs.reshape(1, -1, 3)
+                        * evaled.reshape(evaled.shape[0], -1, 1)
+                    )
+                    .sum(dim=1)
+                    .detach()
+                )
             # ic(E.mean(), bg_module.mean_color())
             diffuse = albedo * E
         else:
@@ -573,7 +590,19 @@ class Microfacet(torch.nn.Module):
             spec[bounce_mask] = row_mask_sum(
                 incoming_light / eray_count * importance_samp_correction, ray_mask
             )
-            # ic(incoming_light.mean(), incoming_light.max(), spec[bounce_mask].min(), spec[bounce_mask].mean(), brdf_weight.max(), brdf_weight.mean(), tinted_ref_rgb.mean())
+            # ic(
+            #     incoming_light.shape,
+            #     incoming_light.mean(),
+            #     incoming_light.max(),
+            #     spec[bounce_mask].min(),
+            #     spec[bounce_mask].mean(),
+            #     brdf_weight.max(),
+            #     brdf_weight.mean(),
+            #     tinted_ref_rgb.mean(),
+            #     diffuse.min(),
+            #     diffuse.max(),
+            #     bg_module.mean_color(),
+            # )
             # ic(importance_samp_correction.min(), importance_samp_correction.max())
 
             if self.detach_bg:
* Unmerged path models/realbounce.py
diff --git a/train.py b/train.py
index 566a612..9fd47f4 100644
--- a/train.py
+++ b/train.py
@@ -1,27 +1,27 @@
-import os
-from tqdm.auto import tqdm
-from modules.tensor_nerf import TensorNeRF
-from renderer import *
-from utils import *
-from torch.optim import lr_scheduler
-from torch.utils.tensorboard import SummaryWriter
 import datetime
-from omegaconf import DictConfig, OmegaConf
+import functools
 import math
-from mutils import normalize
-
-from dataLoader import dataset_dict
+import os
 import sys
-import hydra
-from omegaconf import OmegaConf
 from pathlib import Path
+
+import hydra
 from loguru import logger
-import functools
+from omegaconf import DictConfig, OmegaConf
+from torch.optim import lr_scheduler
+from torch.utils.tensorboard import SummaryWriter
+from tqdm.auto import tqdm
+
+from dataLoader import dataset_dict
 from modules.integral_equirect import IntegralEquirect
+from modules.tensor_nerf import TensorNeRF
+from mutils import normalize
+from renderer import *
+from utils import *
 
-os.environ["OPENCV_IO_ENABLE_OPENEXR"]="1"
+os.environ["OPENCV_IO_ENABLE_OPENEXR"] = "1"
 
-# torch.autograd.set_detect_anomaly(True)
+torch.autograd.set_detect_anomaly(True)
 
 # from torch.profiler import profile, record_function, ProfilerActivity
 
@@ -40,18 +40,19 @@ class SimpleSampler:
 
     def nextids(self, batch=None):
         batch = self.batch if batch is None else batch
-        self.curr+=batch
+        self.curr += batch
         if self.curr + batch > self.total:
             self.ids = torch.LongTensor(np.random.permutation(self.total))
             self.curr = 0
-        ids = self.ids[self.curr:self.curr+batch]
+        ids = self.ids[self.curr : self.curr + batch]
         return ids, ids
 
+
 @torch.no_grad()
 def render_test(args):
     params = args.model.params
     if not os.path.exists(args.ckpt):
-        logger.info('the ckpt path does not exists!!')
+        logger.info("the ckpt path does not exists!!")
         return
 
     expname = f"{args.dataset.scenedir.split('/')[-1]}_{args.expname}"
@@ -60,29 +61,38 @@ def render_test(args):
 
     # init dataset
     dataset = dataset_dict[args.dataset.dataset_name]
-    test_dataset = dataset(os.path.join(args.datadir, args.dataset.scenedir), split='test', downsample=args.dataset.downsample_train, is_stack=True, white_bg=white_bg)
+    test_dataset = dataset(
+        os.path.join(args.datadir, args.dataset.scenedir),
+        split="test",
+        downsample=args.dataset.downsample_train,
+        is_stack=True,
+        white_bg=white_bg,
+    )
     white_bg = test_dataset.white_bg
     ndc_ray = args.dataset.ndc_ray
 
     ckpt = torch.load(args.ckpt)
-    tensorf = TensorNeRF.load(ckpt, args.model.arch, near_far=test_dataset.near_far, strict=False)
+    tensorf = TensorNeRF.load(
+        ckpt, args.model.arch, near_far=test_dataset.near_far, strict=False
+    )
 
     if args.fixed_bg is not None:
         bg_sd = torch.load(args.fixed_bg)
         from modules import bg_modules
+
         # bg_module = bg_modules.HierarchicalCubeMap(bg_resolution=2048, num_levels=1, featureC=128, activation='softplus', power=2, lr=1e-2)
         bg_module = IntegralEquirect(
-            bg_resolution = 1024,
-            mipbias = 0,
-            activation = 'exp',
-            lr = 0.001,
-            init_val = -1.897,
-            mul_lr = 0.001,
-            brightness_lr = 0,
-            betas = [0.0, 0.0],
-            mul_betas = [0.9, 0.9],
-            mipbias_lr = 1e-4,
-            mipnoise = 0.0
+            bg_resolution=1024,
+            mipbias=0,
+            activation="exp",
+            lr=0.001,
+            init_val=-1.897,
+            mul_lr=0.001,
+            brightness_lr=0,
+            betas=[0.0, 0.0],
+            mul_betas=[0.9, 0.9],
+            mipbias_lr=1e-4,
+            mipnoise=0.0,
         )
         bg_module.load_state_dict(bg_sd, strict=False)
         bg_module.lr = 0
@@ -117,18 +127,47 @@ def render_test(args):
 
     logfolder = os.path.dirname(args.ckpt)
     if args.render_train:
-        os.makedirs(f'{logfolder}/imgs_train_all', exist_ok=True)
-        train_dataset = dataset(os.path.join(args.datadir, args.dataset.scenedir), split='train', downsample=args.dataset.downsample_train, is_stack=True, white_bg=white_bg, is_testing=True)
-        test_res = evaluation(train_dataset,tensorf, args, renderer, f'{logfolder}/imgs_train_all/',
-                                N_vis=-1, N_samples=-1, white_bg = white_bg, ndc_ray=ndc_ray,device=device)
-        logger.info(f'======> {expname} train all psnr: {np.mean(test_res["psnrs"])} <========================')
+        os.makedirs(f"{logfolder}/imgs_train_all", exist_ok=True)
+        train_dataset = dataset(
+            os.path.join(args.datadir, args.dataset.scenedir),
+            split="train",
+            downsample=args.dataset.downsample_train,
+            is_stack=True,
+            white_bg=white_bg,
+            is_testing=True,
+        )
+        test_res = evaluation(
+            train_dataset,
+            tensorf,
+            args,
+            renderer,
+            f"{logfolder}/imgs_train_all/",
+            N_vis=-1,
+            N_samples=-1,
+            white_bg=white_bg,
+            ndc_ray=ndc_ray,
+            device=device,
+        )
+        logger.info(
+            f'======> {expname} train all psnr: {np.mean(test_res["psnrs"])} <========================'
+        )
 
     if args.render_test:
-        folder = f'{logfolder}/imgs_test_all'
+        folder = f"{logfolder}/imgs_test_all"
         os.makedirs(folder, exist_ok=True)
         logger.info(f"Saving test to {folder}")
-        evaluation(test_dataset,tensorf, args, renderer, folder,
-                   N_vis=-1, N_samples=-1, white_bg = white_bg, ndc_ray=ndc_ray,device=device)
+        evaluation(
+            test_dataset,
+            tensorf,
+            args,
+            renderer,
+            folder,
+            N_vis=-1,
+            N_samples=-1,
+            white_bg=white_bg,
+            ndc_ray=ndc_ray,
+            device=device,
+        )
 
     #  if args.render_path:
     #      c2ws = test_dataset.render_path
@@ -136,6 +175,7 @@ def render_test(args):
     #      evaluation_path(test_dataset,tensorf, c2ws, renderer, f'{logfolder}/{args.expname}/imgs_path_all/',
     #                      N_vis=-1, N_samples=-1, white_bg = white_bg, ndc_ray=ndc_ray,device=device, bundle_size=args.bundle_size)
 
+
 def reconstruction(args):
     params = args.model.params
     expname = f"{args.dataset.scenedir.split('/')[-1]}_{args.expname}"
@@ -143,12 +183,26 @@ def reconstruction(args):
 
     # init dataset
     dataset = dataset_dict[args.dataset.dataset_name]
-    stack_norms = args.dataset.stack_norms if hasattr(args.dataset, 'stack_norms') else False
-    white_bg = args.dataset.white_bg if hasattr(args.dataset, 'white_bg') else True
-    train_dataset = dataset(os.path.join(args.datadir, args.dataset.scenedir), split='train',
-                            downsample=args.dataset.downsample_train, is_stack=False, stack_norms=stack_norms, white_bg=white_bg)
-    test_dataset = dataset(os.path.join(args.datadir, args.dataset.scenedir), split='test',
-                           downsample=args.dataset.downsample_train, is_stack=True, white_bg=white_bg, is_testing=True)
+    stack_norms = (
+        args.dataset.stack_norms if hasattr(args.dataset, "stack_norms") else False
+    )
+    white_bg = args.dataset.white_bg if hasattr(args.dataset, "white_bg") else True
+    train_dataset = dataset(
+        os.path.join(args.datadir, args.dataset.scenedir),
+        split="train",
+        downsample=args.dataset.downsample_train,
+        is_stack=False,
+        stack_norms=stack_norms,
+        white_bg=white_bg,
+    )
+    test_dataset = dataset(
+        os.path.join(args.datadir, args.dataset.scenedir),
+        split="test",
+        downsample=args.dataset.downsample_train,
+        is_stack=True,
+        white_bg=white_bg,
+        is_testing=True,
+    )
     white_bg = train_dataset.white_bg
     train_dataset.near_far = args.dataset.near_far
     near_far = train_dataset.near_far
@@ -157,19 +211,22 @@ def reconstruction(args):
     if args.add_timestamp:
         logfolder = f'{args.basedir}/{expname}{datetime.datetime.now().strftime("-%Y%m%d-%H%M%S")}'
     else:
-        logfolder = f'{args.basedir}/{expname}'
+        logfolder = f"{args.basedir}/{expname}"
     logger.add(logfolder + "/{time}.log", level="INFO", rotation="100 MB")
-    
 
     # init log file
     os.makedirs(logfolder, exist_ok=True)
-    os.makedirs(f'{logfolder}/imgs_vis', exist_ok=True)
+    os.makedirs(f"{logfolder}/imgs_vis", exist_ok=True)
     summary_writer = SummaryWriter(logfolder)
 
-    aabb_scale = 1 if not hasattr(args.dataset, "aabb_scale") else args.dataset.aabb_scale
+    aabb_scale = (
+        1 if not hasattr(args.dataset, "aabb_scale") else args.dataset.aabb_scale
+    )
     aabb = train_dataset.scene_bbox.to(device) * aabb_scale
 
-    tensorf = hydra.utils.instantiate(args.model.arch)(aabb=aabb, near_far=train_dataset.near_far)
+    tensorf = hydra.utils.instantiate(args.model.arch)(
+        aabb=aabb, near_far=train_dataset.near_far
+    )
     if args.ckpt is not None:
         # TODO REMOVE
         ckpt = torch.load(args.ckpt)
@@ -196,17 +253,17 @@ def reconstruction(args):
         # if tensorf.bright_sampler is not None:
         #     tensorf.bright_sampler.update(tensorf.bg_module)
         bg_module = IntegralEquirect(
-            bg_resolution = 1024,
-            mipbias = 0,
-            activation = 'exp',
-            lr = 0.001,
-            init_val = -1.897,
-            mul_lr = 0.001,
-            brightness_lr = 0,
-            betas = [0.0, 0.0],
-            mul_betas = [0.9, 0.9],
-            mipbias_lr = 1e-4,
-            mipnoise = 0.0
+            bg_resolution=1024,
+            mipbias=0,
+            activation="exp",
+            lr=0.001,
+            init_val=-1.897,
+            mul_lr=0.001,
+            brightness_lr=0,
+            betas=[0.0, 0.0],
+            mul_betas=[0.9, 0.9],
+            mipbias_lr=1e-4,
+            mipnoise=0.0,
         )
         bg_module.load_state_dict(bg_sd)
         bg_module.lr = 0
@@ -220,34 +277,36 @@ def reconstruction(args):
     lr_bg = 1e-5
     grad_vars = tensorf.get_optparam_groups()
     if args.lr_decay_iters > 0:
-        lr_factor = args.lr_decay_target_ratio**(1/args.lr_decay_iters)
+        lr_factor = args.lr_decay_target_ratio ** (1 / args.lr_decay_iters)
     else:
         args.lr_decay_iters = params.n_iters
-        lr_factor = args.lr_decay_target_ratio**(1/params.n_iters)
+        lr_factor = args.lr_decay_target_ratio ** (1 / params.n_iters)
 
     # smoothing_vals = [0.6, 0.7, 0.8, 0.7, 0.5]
-    upsamp_bg = hasattr(params, 'bg_upsamp_res') and tensorf.bg_module is not None
+    upsamp_bg = hasattr(params, "bg_upsamp_res") and tensorf.bg_module is not None
     if upsamp_bg:
         res = params.bg_upsamp_res.pop(0)
         lr_bg = params.bg_upsamp_lr.pop(0)
         logger.info(f"Upsampling bg to {res}")
         tensorf.bg_module.upsample(res)
-        ind = [i for i, d in enumerate(grad_vars) if 'name' in d and d['name'] == 'bg'][0]
-        grad_vars[ind]['params'] = tensorf.bg_module.parameters()
-        grad_vars[ind]['lr'] = lr_bg
-
+        ind = [i for i, d in enumerate(grad_vars) if "name" in d and d["name"] == "bg"][
+            0
+        ]
+        grad_vars[ind]["params"] = tensorf.bg_module.parameters()
+        grad_vars[ind]["lr"] = lr_bg
 
     torch.cuda.empty_cache()
-    PSNRs,PSNRs_test = [],[0]
+    PSNRs, PSNRs_test = [], [0]
 
     allrays, allrgbs = train_dataset.all_rays, train_dataset.all_rgbs
     if not ndc_ray and args.filter_rays:
-        allrays, allrgbs, mask = tensorf.filtering_rays(allrays, allrgbs, train_dataset.focal, bbox_only=True)
+        allrays, allrgbs, mask = tensorf.filtering_rays(
+            allrays, allrgbs, train_dataset.focal, bbox_only=True
+        )
     else:
         mask = None
     trainingSampler = SimpleSampler(allrays.shape[0], params.batch_size)
 
-
     ortho_reg_weight = params.ortho_weight
     logger.info("initial ortho_reg_weight", ortho_reg_weight)
 
@@ -255,12 +314,14 @@ def reconstruction(args):
     logger.info("initial L1_reg_weight", L1_reg_weight)
     TV_weight_density, TV_weight_app = params.TV_weight_density, params.TV_weight_app
     tvreg = TVLoss()
-    logger.info(f"initial TV_weight density: {TV_weight_density} appearance: {TV_weight_app}")
+    logger.info(
+        f"initial TV_weight density: {TV_weight_density} appearance: {TV_weight_app}"
+    )
 
     # allrgbs = allrgbs.to(device)
     # allrays = allrays.to(device)
     # ratio of meters to pixels at a distance of 1 meter
-    focal = (train_dataset.focal[0] if ndc_ray else train_dataset.fx)
+    focal = train_dataset.focal[0] if ndc_ray else train_dataset.fx
     # / train_dataset.img_wh[0]
     # with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], with_stack=True, record_shapes=True) as prof:
     logger.info(tensorf)
@@ -286,7 +347,7 @@ def reconstruction(args):
     #             optimizer.step()
     #             photo_loss = loss.detach().item()
     #             pbar.set_description(f'psnr={-10.0 * np.log(photo_loss) / np.log(10.0):.04f}')
-        # tensorf.bg_module.save('test.png')
+    # tensorf.bg_module.save('test.png')
 
     tensorf.sampler.update(tensorf.rf, init=True)
     # TODO REMOVE
@@ -294,35 +355,50 @@ def reconstruction(args):
         if tensorf.rf.num_pretrain > 0:
             # dparams = tensorf.parameters()
             # space_optim = torch.optim.Adam(tensorf.rf.dbasis_mat.parameters(), lr=0.5, betas=(0.9,0.99))
-            space_optim = torch.optim.Adam(tensorf.parameters(), lr=0.005, betas=(0.9,0.99))
+            space_optim = torch.optim.Adam(
+                tensorf.parameters(), lr=0.005, betas=(0.9, 0.99)
+            )
             pbar = tqdm(range(tensorf.rf.num_pretrain))
             for _ in pbar:
-                xyz = (torch.rand(20000, 3, device=device)*2-1) * tensorf.rf.aabb[1].reshape(1, 3)
+                xyz = (torch.rand(20000, 3, device=device) * 2 - 1) * tensorf.rf.aabb[
+                    1
+                ].reshape(1, 3)
                 sigma_feat = tensorf.rf.compute_densityfeature(xyz)
 
                 # step_size = 0.015
                 step_size = tensorf.sampler.stepsize
-                alpha = 1-torch.exp(-sigma_feat * step_size * tensorf.rf.distance_scale)
+                alpha = 1 - torch.exp(
+                    -sigma_feat * step_size * tensorf.rf.distance_scale
+                )
                 # ic(alpha.mean(), sigma_feat.mean(), tensorf.rf.distance_scale)
                 # sigma = 1-torch.exp(-sigma_feat)
                 # loss = (sigma-torch.rand_like(sigma)*args.start_density).abs().mean()
                 # target_alpha = (params.start_density+params.start_density*(2*torch.rand_like(alpha)-1))
-                target_alpha = (params.start_density + 0.1*params.start_density*torch.randn_like(alpha))
+                target_alpha = (
+                    params.start_density
+                    + 0.1 * params.start_density * torch.randn_like(alpha)
+                )
                 # target_alpha = target_alpha.clip(min=params.start_density/2, max=params.start_density*2)
                 # target_alpha = params.start_density
-                loss = (alpha-target_alpha).abs().mean()
+                loss = (alpha - target_alpha).abs().mean()
                 # loss = (-sigma[mask].clip(max=1).sum() + sigma[~mask].clip(min=1e-8).sum())
                 space_optim.zero_grad()
                 loss.backward()
-                pbar.set_description(f"Mean alpha: {alpha.detach().mean().item():.06f}.")
+                pbar.set_description(
+                    f"Mean alpha: {alpha.detach().mean().item():.06f}."
+                )
                 space_optim.step()
         elif tensorf.rf.calibrate:
             # calculate alpha mean
-            xyz = (torch.rand(20000, 3, device=device)*2-1) * tensorf.rf.aabb[1].reshape(1, 3)
+            xyz = (torch.rand(20000, 3, device=device) * 2 - 1) * tensorf.rf.aabb[
+                1
+            ].reshape(1, 3)
             sigma_feat = tensorf.rf.compute_densityfeature(xyz)
 
             # step_size = 0.015
-            target_sigma = -math.log(1-params.start_density) / (tensorf.sampler.stepsize * tensorf.rf.distance_scale)
+            target_sigma = -math.log(1 - params.start_density) / (
+                tensorf.sampler.stepsize * tensorf.rf.distance_scale
+            )
 
             # compute density_shift assume exponential activation
             density_shift = math.log(target_sigma) - math.log(sigma_feat.mean().item())
@@ -330,118 +406,198 @@ def reconstruction(args):
             tensorf.rf.density_shift += density_shift
             args.field.density_shift = tensorf.rf.density_shift
     # tensorf.sampler.mark_untrained_grid(train_dataset.poses, train_dataset.intrinsics)
-    xyz = (torch.rand(20000, 3, device=device)*2-1) * tensorf.rf.aabb[1].reshape(1, 3)
+    xyz = (torch.rand(20000, 3, device=device) * 2 - 1) * tensorf.rf.aabb[1].reshape(
+        1, 3
+    )
     sigma_feat = tensorf.rf.compute_densityfeature(xyz)
     torch.cuda.empty_cache()
     tensorf.sampler.update(tensorf.rf, init=True)
     torch.cuda.empty_cache()
 
-
-    xyz = torch.rand(100000, 4, device=device)*2-1
+    xyz = torch.rand(100000, 4, device=device) * 2 - 1
     xyz[:, 3] *= 0
     sigma_feat = tensorf.rf.compute_densityfeature(xyz)
-    alpha = 1-torch.exp(-sigma_feat * tensorf.sampler.stepsize * tensorf.rf.distance_scale)
+    alpha = 1 - torch.exp(
+        -sigma_feat * tensorf.sampler.stepsize * tensorf.rf.distance_scale
+    )
     feat = tensorf.rf.compute_appfeature(xyz)
     bg_brightness = tensorf.bg_module.mean_color().detach().mean()
     args = tensorf.model.calibrate(args, xyz, feat, bg_brightness)
 
-    pbar = tqdm(range(params.n_iters), miniters=args.progress_refresh_rate, file=sys.stdout)
+    pbar = tqdm(
+        range(params.n_iters), miniters=args.progress_refresh_rate, file=sys.stdout
+    )
+
     def init_optimizer(grad_vars):
         # optimizer = torch.optim.Adam(grad_vars, betas=(0.9, 0.999), weight_decay=0, eps=1e-6)
         optimizer = torch.optim.Adam(grad_vars, betas=params.betas, eps=params.eps)
         if params.lr is not None:
-            optimizer = torch.optim.Adam(tensorf.parameters(), lr=params.lr, betas=params.betas, eps=params.eps)
+            optimizer = torch.optim.Adam(
+                tensorf.parameters(), lr=params.lr, betas=params.betas, eps=params.eps
+            )
         else:
-            optimizer = torch.optim.Adam(grad_vars, betas=params.betas, eps=params.eps, weight_decay=params.weight_decay)
+            optimizer = torch.optim.Adam(
+                grad_vars,
+                betas=params.betas,
+                eps=params.eps,
+                weight_decay=params.weight_decay,
+            )
         compute_lambda = functools.partial(
-                learning_rate_decay, lr_init=params.lr_init, lr_final=params.lr_final, max_steps=params.n_iters,
-                lr_delay_steps=params.lr_delay_steps, lr_delay_mult=params.lr_delay_mult)
+            learning_rate_decay,
+            lr_init=params.lr_init,
+            lr_final=params.lr_final,
+            max_steps=params.n_iters,
+            lr_delay_steps=params.lr_delay_steps,
+            lr_delay_mult=params.lr_delay_mult,
+        )
         scheduler = lr_scheduler.LambdaLR(optimizer, compute_lambda)
         return optimizer, scheduler
+
     optimizer, scheduler = init_optimizer(grad_vars)
-    ori_decay = math.exp(math.log(params.final_ori_lambda / params.ori_lambda) / params.n_iters) if params.ori_lambda > 0 and params.final_ori_lambda is not None else 1
-    normal_decay = math.exp(math.log(params.final_pred_lambda / params.pred_lambda) / params.n_iters) if params.pred_lambda > 0 and params.final_pred_lambda is not None else 1
+    ori_decay = (
+        math.exp(math.log(params.final_ori_lambda / params.ori_lambda) / params.n_iters)
+        if params.ori_lambda > 0 and params.final_ori_lambda is not None
+        else 1
+    )
+    normal_decay = (
+        math.exp(
+            math.log(params.final_pred_lambda / params.pred_lambda) / params.n_iters
+        )
+        if params.pred_lambda > 0 and params.final_pred_lambda is not None
+        else 1
+    )
     ic(ori_decay)
     ic(normal_decay)
 
-    OmegaConf.save(config=args, f=f'{logfolder}/config.yaml')
+    OmegaConf.save(config=args, f=f"{logfolder}/config.yaml")
     num_rays = params.starting_batch_size
     prev_n_samples = None
     hist_n_samples = None
     gt_bg_path = args.gt_bg if args.gt_bg is not None else None
-    if hasattr(args.dataset, 'gt_bg') and args.dataset.gt_bg is not None:
-        gt_bg_path = Path('backgrounds') / args.dataset.gt_bg
+    if hasattr(args.dataset, "gt_bg") and args.dataset.gt_bg is not None:
+        gt_bg_path = Path("backgrounds") / args.dataset.gt_bg
     ic(gt_bg_path)
     gt_bg = cv2.imread(str(gt_bg_path)) if gt_bg_path is not None else None
     if True:
-    # with torch.profiler.profile(record_shapes=True, schedule=torch.profiler.schedule(wait=1, warmup=1, active=params.n_iters-1), with_stack=True) as p:
-    # with torch.autograd.detect_anomaly():
+        # with torch.profiler.profile(record_shapes=True, schedule=torch.profiler.schedule(wait=1, warmup=1, active=params.n_iters-1), with_stack=True) as p:
+        # with torch.autograd.detect_anomaly():
         for iteration in pbar:
             optimizer.zero_grad(set_to_none=True)
-            losses, roughnesses, envmap_regs, diffuse_regs = [],[],[],[]
+            losses, roughnesses, envmap_regs, diffuse_regs = [], [], [], []
             brdf_regs = []
             pred_losses, ori_losses = [], []
             TVs = []
 
-            lbatch_size = min(params.min_batch_size if num_rays < params.min_batch_size else num_rays, params.max_batch_size)
+            lbatch_size = min(
+                params.min_batch_size if num_rays < params.min_batch_size else num_rays,
+                params.max_batch_size,
+            )
             num_remaining = lbatch_size
             while num_remaining > 0:
                 lnum_rays = min(num_rays, num_remaining)
                 num_remaining -= lnum_rays
                 ray_idx, rgb_idx = trainingSampler.nextids(lnum_rays)
-                rays_train, rgba_train = allrays[ray_idx].to(device), allrgbs[rgb_idx].reshape(-1, allrgbs.shape[-1]).to(device)
+                rays_train, rgba_train = allrays[ray_idx].to(device), allrgbs[
+                    rgb_idx
+                ].reshape(-1, allrgbs.shape[-1]).to(device)
                 match params.bg_col:
-                    case 'rand':
+                    case "rand":
                         bg_col = torch.rand(3, device=device)
-                    case 'white':
+                    case "white":
                         bg_col = torch.ones((3), device=device)
-                    case 'black':
+                    case "black":
                         bg_col = torch.zeros((3), device=device)
                     case _:
                         raise Exception(f"Unknown bg col: {params.bg_col}")
                 if rgba_train.shape[-1] == 4:
-                    rgb_train = rgba_train[:, :3] * rgba_train[:, -1:] + (1 - rgba_train[:, -1:])*bg_col  # blend A to RGB
+                    rgb_train = (
+                        rgba_train[:, :3] * rgba_train[:, -1:]
+                        + (1 - rgba_train[:, -1:]) * bg_col
+                    )  # blend A to RGB
                     alpha_train = rgba_train[..., 3]
                 else:
                     rgb_train = rgba_train
                     alpha_train = None
-                gt_normal_map = train_dataset.all_norms[ray_idx].to(device) if train_dataset.stack_norms else None
+                gt_normal_map = (
+                    train_dataset.all_norms[ray_idx].to(device)
+                    if train_dataset.stack_norms
+                    else None
+                )
 
                 with torch.cuda.amp.autocast(enabled=args.fp16):
-                    ims, stats = renderer(rays_train, tensorf, gt_normals=gt_normal_map,
-                            keys = ['rgb_map', 'normal_err', 'distortion_loss', 'prediction_loss', 'ori_loss', 'diffuse_reg', 'roughness', 'whole_valid', 'envmap_reg', 'brdf_reg', 'n_samples'],
-                            focal=focal, output_alpha=alpha_train, chunk=num_rays, bg_col=bg_col, is_train=True, ndc_ray=ndc_ray)
-
-                    n_samples = stats['n_samples']
+                    ims, stats = renderer(
+                        rays_train,
+                        tensorf,
+                        gt_normals=gt_normal_map,
+                        keys=[
+                            "rgb_map",
+                            "normal_err",
+                            "distortion_loss",
+                            "prediction_loss",
+                            "ori_loss",
+                            "diffuse_reg",
+                            "roughness",
+                            "whole_valid",
+                            "envmap_reg",
+                            "brdf_reg",
+                            "n_samples",
+                        ],
+                        focal=focal,
+                        output_alpha=alpha_train,
+                        chunk=num_rays,
+                        bg_col=bg_col,
+                        is_train=True,
+                        ndc_ray=ndc_ray,
+                    )
+
+                    n_samples = stats["n_samples"]
                     if n_samples[0] == 0:
                         continue
-                    prediction_loss = stats['prediction_loss'].sum()
-                    distortion_loss = stats['distortion_loss'].sum()
-                    diffuse_reg = stats['diffuse_reg'].sum()
-                    envmap_reg = stats['envmap_reg'].sum()
-                    brdf_reg = stats['brdf_reg'].sum()
-                    rgb_map = ims['rgb_map']
+                    prediction_loss = stats["prediction_loss"].sum()
+                    distortion_loss = stats["distortion_loss"].sum()
+                    diffuse_reg = stats["diffuse_reg"].sum()
+                    envmap_reg = stats["envmap_reg"].sum()
+                    brdf_reg = stats["brdf_reg"].sum()
+                    rgb_map = ims["rgb_map"]
                     if not train_dataset.hdr:
                         rgb_map = rgb_map.clip(max=1)
-                    whole_valid = stats['whole_valid'] 
+                    whole_valid = stats["whole_valid"]
                     if params.charbonier_loss:
-                        loss = torch.sqrt((rgb_map - rgb_train[whole_valid]) ** 2 + params.charbonier_eps**2).sum()
+                        loss = torch.sqrt(
+                            (rgb_map - rgb_train[whole_valid]) ** 2
+                            + params.charbonier_eps**2
+                        ).sum()
                     else:
                         # loss = ((rgb_map - rgb_train[whole_valid]) ** 2).mean()
                         # loss = F.huber_loss(rgb_map.clip(0, 1), rgb_train[whole_valid], delta=1, reduction='mean')
-                        loss = ((rgb_map.clip(0, 1) - rgb_train[whole_valid].clip(0, 1))**2).sum()
+                        loss = (
+                            (rgb_map.clip(0, 1) - rgb_train[whole_valid].clip(0, 1))
+                            ** 2
+                        ).sum()
                         # loss = ((rgb_map.clip(0, 1) - rgb_train[whole_valid].clip(0, 1)).abs()).sum()
-                    norm_err = sum(stats['normal_err']) if type(stats['normal_err']) == list else stats['normal_err'].sum()
+                    norm_err = (
+                        sum(stats["normal_err"])
+                        if type(stats["normal_err"]) == list
+                        else stats["normal_err"].sum()
+                    )
                     # loss = torch.sqrt(F.huber_loss(rgb_map, rgb_train, delta=1, reduction='none') + params.charbonier_eps**2).mean()
                     # photo_loss = ((rgb_map.clip(0, 1) - rgb_train[whole_valid].clip(0, 1)) ** 2).mean().detach()
-                    photo_loss = ((rgb_map.clip(0, 1) - rgb_train[whole_valid].clip(0, 1))**2).mean().detach()
-                    ori_loss = stats['ori_loss'].sum()
+                    photo_loss = (
+                        ((rgb_map.clip(0, 1) - rgb_train[whole_valid].clip(0, 1)) ** 2)
+                        .mean()
+                        .detach()
+                    )
+                    ori_loss = stats["ori_loss"].sum()
 
                     # adjust number of rays
                     # need to store mean ratios if I have any hope of stabilizing this
                     mean_samples = n_samples
                     ratio = int(whole_valid.sum()) / mean_samples[0]
-                    mean_ratio = ratio if prev_n_samples is None else min(0.1*ratio + 0.9*prev_n_samples, ratio)
+                    mean_ratio = (
+                        ratio
+                        if prev_n_samples is None
+                        else min(0.1 * ratio + 0.9 * prev_n_samples, ratio)
+                    )
                     prev_n_samples = mean_ratio
                     num_rays = int(mean_ratio * params.target_num_samples + 1)
                     tensorf.model.update_n_samples(n_samples[1:])
@@ -458,67 +614,94 @@ def reconstruction(args):
                     # pred_lambda = params.pred_lambda if iteration > 500 else params.pred_lambda * iteration / 500
                     ori_lambda = params.ori_lambda
                     pred_lambda = params.pred_lambda
-                    # ic(pred_lambda, ori_lambda, loss, 
+                    # ic(pred_lambda, ori_lambda, loss,
                     #     params.distortion_lambda*distortion_loss,
                     #     ori_lambda*ori_loss,
                     #     params.envmap_lambda * (envmap_reg-0.05).clip(min=0),
                     #     params.diffuse_lambda * diffuse_reg,
                     #     params.brdf_lambda * brdf_reg,
                     #     pred_lambda * prediction_loss)
-                    total_loss = loss + \
-                        params.distortion_lambda*distortion_loss + \
-                        ori_lambda*ori_loss + \
-                        params.envmap_lambda * envmap_reg + \
-                        params.diffuse_lambda * diffuse_reg + \
-                        params.brdf_lambda * brdf_reg + \
-                        pred_lambda * prediction_loss + \
-                        params.normal_err_lambda * norm_err
-
+                    total_loss = (
+                        loss
+                        + params.distortion_lambda * distortion_loss
+                        + ori_lambda * ori_loss
+                        + params.envmap_lambda * envmap_reg
+                        + params.diffuse_lambda * diffuse_reg
+                        + params.brdf_lambda * brdf_reg
+                        + pred_lambda * prediction_loss
+                        + params.normal_err_lambda * norm_err
+                    )
 
                     # if tensorf.visibility_module is not None:
-                        # pass
-                        # if iteration % 1 == 0 and iteration > 250:
-                        #     # if iteration < 100 or iteration % 1000 == 0:
-                        #     if iteration % 250 == 0 and iteration < 2000:
-                        #         tensorf.init_vis_module()
-                        #         torch.cuda.empty_cache()
-                        #     else:
-                        #         tensorf.compute_visibility_loss(params.N_visibility_rays)
+                    # pass
+                    # if iteration % 1 == 0 and iteration > 250:
+                    #     # if iteration < 100 or iteration % 1000 == 0:
+                    #     if iteration % 250 == 0 and iteration < 2000:
+                    #         tensorf.init_vis_module()
+                    #         torch.cuda.empty_cache()
+                    #     else:
+                    #         tensorf.compute_visibility_loss(params.N_visibility_rays)
 
                     if ortho_reg_weight > 0:
                         loss_reg = tensorf.rf.vector_comp_diffs()
-                        total_loss += ortho_reg_weight*loss_reg
-                        summary_writer.add_scalar('train/reg', loss_reg.detach().item(), global_step=iteration)
+                        total_loss += ortho_reg_weight * loss_reg
+                        summary_writer.add_scalar(
+                            "train/reg", loss_reg.detach().item(), global_step=iteration
+                        )
                     if L1_reg_weight > 0:
                         loss_reg_L1 = tensorf.rf.density_L1()
-                        total_loss += L1_reg_weight*loss_reg_L1
-                        summary_writer.add_scalar('train/reg_l1', loss_reg_L1.detach().item(), global_step=iteration)
+                        total_loss += L1_reg_weight * loss_reg_L1
+                        summary_writer.add_scalar(
+                            "train/reg_l1",
+                            loss_reg_L1.detach().item(),
+                            global_step=iteration,
+                        )
 
                     loss_tv = 0
-                    if TV_weight_density>0:
+                    if TV_weight_density > 0:
                         TV_weight_density *= lr_factor
                         loss_tv = tensorf.rf.TV_loss_density(tvreg) * TV_weight_density
-                        summary_writer.add_scalar('train/reg_tv_density', loss_tv.detach().item(), global_step=iteration)
-                    if TV_weight_app>0:
+                        summary_writer.add_scalar(
+                            "train/reg_tv_density",
+                            loss_tv.detach().item(),
+                            global_step=iteration,
+                        )
+                    if TV_weight_app > 0:
                         TV_weight_app *= lr_factor
-                        loss_tv = loss_tv + tensorf.rf.TV_loss_app(tvreg)*TV_weight_app
-                        summary_writer.add_scalar('train/reg_tv_app', loss_tv.detach().item(), global_step=iteration)
+                        loss_tv = (
+                            loss_tv + tensorf.rf.TV_loss_app(tvreg) * TV_weight_app
+                        )
+                        summary_writer.add_scalar(
+                            "train/reg_tv_app",
+                            loss_tv.detach().item(),
+                            global_step=iteration,
+                        )
                     if params.TV_weight_bg > 0:
-                        loss_tv = loss_tv + params.TV_weight_bg*tensorf.bg_module.tv_loss()
+                        loss_tv = (
+                            loss_tv + params.TV_weight_bg * tensorf.bg_module.tv_loss()
+                        )
                     total_loss = total_loss + loss_tv
 
                     total_loss = total_loss / lbatch_size
                     total_loss.backward()
 
                     photo_loss = photo_loss.detach().item()
-                
+
                     TVs.append(float(loss_tv))
                     ori_losses.append(params.ori_lambda * ori_loss.detach().item())
-                    pred_losses.append(params.pred_lambda * prediction_loss.detach().item())
+                    pred_losses.append(
+                        params.pred_lambda * prediction_loss.detach().item()
+                    )
                     losses.append(total_loss.detach().item())
                     # roughnesses.append(ims['roughness'].mean().detach().item())
-                    diffuse_regs.append(params.diffuse_lambda * diffuse_reg.detach().item() / lbatch_size)
-                    envmap_regs.append(params.envmap_lambda * envmap_reg.detach().item() / lbatch_size)
+                    diffuse_regs.append(
+                        params.diffuse_lambda
+                        * diffuse_reg.detach().item()
+                        / lbatch_size
+                    )
+                    envmap_regs.append(
+                        params.envmap_lambda * envmap_reg.detach().item() / lbatch_size
+                    )
                     brdf_regs.append(params.brdf_lambda * brdf_reg.detach().item())
                     PSNRs.append(-10.0 * np.log(photo_loss) / np.log(10.0))
 
@@ -538,38 +721,57 @@ def reconstruction(args):
             scheduler.step()
             params.ori_lambda *= ori_decay
             params.pred_lambda *= normal_decay
-                
-            if iteration % args.vis_every == args.vis_every - 1 and args.N_vis!=0:
+
+            if iteration % args.vis_every == args.vis_every - 1 and args.N_vis != 0:
                 # tensorf.save(f'{logfolder}/{expname}_{iteration}.th', args.model.arch)
                 torch.cuda.empty_cache()
-                test_res = evaluation(test_dataset,tensorf, args, renderer, f'{logfolder}/imgs_vis/', N_vis=args.N_vis,
-                                        prtx=f'{iteration:06d}_', white_bg = white_bg, ndc_ray=ndc_ray,
-                                        compute_extra_metrics=False, gt_bg=gt_bg)
-                PSNRs_test = test_res['psnrs']
-                summary_writer.add_scalar('test/psnr', np.mean(test_res['psnrs']), global_step=iteration)
-                summary_writer.add_scalar('test/norm_err', np.mean(test_res['norm_errs']), global_step=iteration)
-                logger.info(f'test_psnr = {float(np.mean(PSNRs_test)):.2f}')
+                test_res = evaluation(
+                    test_dataset,
+                    tensorf,
+                    args,
+                    renderer,
+                    f"{logfolder}/imgs_vis/",
+                    N_vis=args.N_vis,
+                    prtx=f"{iteration:06d}_",
+                    white_bg=white_bg,
+                    ndc_ray=ndc_ray,
+                    compute_extra_metrics=False,
+                    gt_bg=gt_bg,
+                )
+                PSNRs_test = test_res["psnrs"]
+                summary_writer.add_scalar(
+                    "test/psnr", np.mean(test_res["psnrs"]), global_step=iteration
+                )
+                summary_writer.add_scalar(
+                    "test/norm_err",
+                    np.mean(test_res["norm_errs"]),
+                    global_step=iteration,
+                )
+                logger.info(f"test_psnr = {float(np.mean(PSNRs_test)):.2f}")
                 if args.save_often:
-                    tensorf.save(f'{logfolder}/{expname}_{iteration:06d}.th', args.model.arch)
+                    tensorf.save(
+                        f"{logfolder}/{expname}_{iteration:06d}.th", args.model.arch
+                    )
 
             # logger.info the current values of the losses.
             if iteration % args.progress_refresh_rate == 0:
-                desc = f'psnr = {float(np.mean(PSNRs)):.2f}' + \
-                    f' test_psnr = {float(np.mean(PSNRs_test)):.2f}' + \
-                    f' loss = {float(np.sum(losses)):.5f}' + \
-                    f' envmap = {float(np.sum(envmap_regs)):.5f}' + \
-                    f' diffuse = {float(np.sum(diffuse_regs)):.5f}' + \
-                    f' brdf = {float(np.sum(brdf_regs)):.5f}' + \
-                    f' nrays = {[num_rays] + tensorf.model.max_retrace_rays}'
-                    # f' rough = {float(np.mean(roughnesses)):.5f}' + \
-                    # f' diffuse = {float(np.sum(diffuse_regs)):.5f}' + \
-                    # f' tv = {float(np.mean(TVs)):.5f}' + \
-                    # f' ori loss = {float(np.mean(ori_losses) / num_rays):.5f}' + \
-                    # f' pred loss = {float(np.mean(pred_losses) / num_rays):.5f}' + \
-                    # + f' mse = {photo_loss:.6f}'
+                desc = (
+                    f"psnr = {float(np.mean(PSNRs)):.2f}"
+                    + f" test_psnr = {float(np.mean(PSNRs_test)):.2f}"
+                    + f" loss = {float(np.sum(losses)):.5f}"
+                    + f" envmap = {float(np.sum(envmap_regs)):.5f}"
+                    + f" diffuse = {float(np.sum(diffuse_regs)):.5f}"
+                    + f" brdf = {float(np.sum(brdf_regs)):.5f}"
+                    + f" nrays = {[num_rays] + tensorf.model.max_retrace_rays}"
+                )
+                # f' rough = {float(np.mean(roughnesses)):.5f}' + \
+                # f' diffuse = {float(np.sum(diffuse_regs)):.5f}' + \
+                # f' tv = {float(np.mean(TVs)):.5f}' + \
+                # f' ori loss = {float(np.mean(ori_losses) / num_rays):.5f}' + \
+                # f' pred loss = {float(np.mean(pred_losses) / num_rays):.5f}' + \
+                # + f' mse = {photo_loss:.6f}'
                 if tensorf.bg_module is not None:
-                    desc = desc + \
-                    f' mipbias = {float(tensorf.bg_module.mipbias):.1e}'
+                    desc = desc + f" mipbias = {float(tensorf.bg_module.mipbias):.1e}"
                     # f' mul = {float(tensorf.bg_module.mul):.1e}' + \
                     # f' bright = {float(tensorf.bg_module.brightness):.1e}'
                 pbar.set_description(desc)
@@ -585,11 +787,10 @@ def reconstruction(args):
 
             # if iteration in update_alphamask_list:
 
-                #  if reso_cur[0] * reso_cur[1] * reso_cur[2]<256**3:# update volume resolution
-                    # tensorVM.alphaMask = None
-                    # L1_reg_weight = params.L1_weight_rest
-                    # logger.info("continuing L1_reg_weight", L1_reg_weight)
-
+            #  if reso_cur[0] * reso_cur[1] * reso_cur[2]<256**3:# update volume resolution
+            # tensorVM.alphaMask = None
+            # L1_reg_weight = params.L1_weight_rest
+            # logger.info("continuing L1_reg_weight", L1_reg_weight)
 
             # if not ndc_ray and iteration == update_AlphaMask_list[-1] and args.filter_rays:
             #     # filter rays outside the bbox
@@ -599,40 +800,78 @@ def reconstruction(args):
     #         p.step()
     # p.export_chrome_trace('p.trace')
 
-
     # prof.export_chrome_trace('trace.json')
-        
-
-    tensorf.save(f'{logfolder}/{expname}.th', args.model.arch)
 
+    tensorf.save(f"{logfolder}/{expname}.th", args.model.arch)
 
     torch.cuda.empty_cache()
     if args.render_train:
-        os.makedirs(f'{logfolder}/imgs_train_all', exist_ok=True)
-        train_dataset = dataset(args.datadir, split='train', downsample=args.downsample_train, is_stack=True)
-        test_res = evaluation(train_dataset,tensorf, args, renderer, f'{logfolder}/imgs_train_all/',
-                                N_vis=-1, N_samples=-1, white_bg = white_bg, ndc_ray=ndc_ray,device=device, gt_bg=gt_bg)
-        logger.info(f'======> {expname} test all psnr: {np.mean(test_res["psnrs"])} <========================')
+        os.makedirs(f"{logfolder}/imgs_train_all", exist_ok=True)
+        train_dataset = dataset(
+            args.datadir, split="train", downsample=args.downsample_train, is_stack=True
+        )
+        test_res = evaluation(
+            train_dataset,
+            tensorf,
+            args,
+            renderer,
+            f"{logfolder}/imgs_train_all/",
+            N_vis=-1,
+            N_samples=-1,
+            white_bg=white_bg,
+            ndc_ray=ndc_ray,
+            device=device,
+            gt_bg=gt_bg,
+        )
+        logger.info(
+            f'======> {expname} test all psnr: {np.mean(test_res["psnrs"])} <========================'
+        )
 
     torch.cuda.empty_cache()
     if args.render_test:
-        os.makedirs(f'{logfolder}/imgs_test_all', exist_ok=True)
-        test_res = evaluation(test_dataset,tensorf, args, renderer, f'{logfolder}/imgs_test_all/',
-                                N_vis=-1, N_samples=-1, white_bg = white_bg, ndc_ray=ndc_ray,device=device, gt_bg=gt_bg)
-        summary_writer.add_scalar('test/psnr_all', np.mean(test_res["psnrs"]), global_step=iteration)
-        logger.info(f'======> {expname} test all psnr: {np.mean(test_res["psnrs"])} <========================')
+        os.makedirs(f"{logfolder}/imgs_test_all", exist_ok=True)
+        test_res = evaluation(
+            test_dataset,
+            tensorf,
+            args,
+            renderer,
+            f"{logfolder}/imgs_test_all/",
+            N_vis=-1,
+            N_samples=-1,
+            white_bg=white_bg,
+            ndc_ray=ndc_ray,
+            device=device,
+            gt_bg=gt_bg,
+        )
+        summary_writer.add_scalar(
+            "test/psnr_all", np.mean(test_res["psnrs"]), global_step=iteration
+        )
+        logger.info(
+            f'======> {expname} test all psnr: {np.mean(test_res["psnrs"])} <========================'
+        )
 
     torch.cuda.empty_cache()
     if args.render_path:
         c2ws = test_dataset.render_path
         # c2ws = test_dataset.poses
-        logger.info('========>',c2ws.shape)
-        os.makedirs(f'{logfolder}/imgs_path_all', exist_ok=True)
-        evaluation_path(test_dataset,tensorf, c2ws, renderer, f'{logfolder}/imgs_path_all/',
-                        N_vis=-1, N_samples=-1, white_bg = white_bg, ndc_ray=ndc_ray,device=device, gt_bg=gt_bg)
+        logger.info("========>", c2ws.shape)
+        os.makedirs(f"{logfolder}/imgs_path_all", exist_ok=True)
+        evaluation_path(
+            test_dataset,
+            tensorf,
+            c2ws,
+            renderer,
+            f"{logfolder}/imgs_path_all/",
+            N_vis=-1,
+            N_samples=-1,
+            white_bg=white_bg,
+            ndc_ray=ndc_ray,
+            device=device,
+            gt_bg=gt_bg,
+        )
 
 
-@hydra.main(version_base=None, config_path='configs', config_name='default')
+@hydra.main(version_base=None, config_path="configs", config_name="default")
 def train(cfg: DictConfig):
     torch.set_default_dtype(torch.float32)
     torch.manual_seed(cfg.seed)
@@ -647,5 +886,6 @@ def train(cfg: DictConfig):
         reconstruction(cfg)
         # reconstruction(args)
 
-if __name__ == '__main__':
+
+if __name__ == "__main__":
     train()
