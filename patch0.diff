diff --git a/configs/dataset/car.yaml b/configs/dataset/car.yaml
new file mode 100644
index 0000000..5b2c5ce
--- /dev/null
+++ b/configs/dataset/car.yaml
@@ -0,0 +1,7 @@
+scenedir: nerf_synthetic/car
+dataset_name: blender
+downsample_train: 1
+downsample_test: 1
+ndc_ray: false
+near_far: [1, 6]
+
diff --git a/configs/dataset/chrome_ball.yaml b/configs/dataset/chrome_ball.yaml
new file mode 100644
index 0000000..a188651
--- /dev/null
+++ b/configs/dataset/chrome_ball.yaml
@@ -0,0 +1,7 @@
+scenedir: nerf_synthetic/chrome_ball
+dataset_name: blender
+downsample_train: 1
+downsample_test: 1
+ndc_ray: false
+near_far: [1, 6]
+
diff --git a/configs/dataset/coffee.yaml b/configs/dataset/coffee.yaml
new file mode 100644
index 0000000..80ac0da
--- /dev/null
+++ b/configs/dataset/coffee.yaml
@@ -0,0 +1,7 @@
+scenedir: nerf_synthetic/coffee
+dataset_name: blender
+downsample_train: 1
+downsample_test: 1
+ndc_ray: false
+near_far: [1, 6]
+
diff --git a/configs/dataset/helmet.yaml b/configs/dataset/helmet.yaml
new file mode 100644
index 0000000..3a6d327
--- /dev/null
+++ b/configs/dataset/helmet.yaml
@@ -0,0 +1,7 @@
+scenedir: nerf_synthetic/helmet
+dataset_name: blender
+downsample_train: 1
+downsample_test: 1
+ndc_ray: false
+near_far: [1, 6]
+
diff --git a/configs/dataset/lego.yaml b/configs/dataset/lego.yaml
index bb66257..61c9a75 100644
--- a/configs/dataset/lego.yaml
+++ b/configs/dataset/lego.yaml
@@ -4,5 +4,4 @@ downsample_train: 1
 downsample_test: 1
 ndc_ray: false
 near_far: [2.5, 7]
-aabb_scale: 1.20
 
diff --git a/configs/dataset/mango_ball.yaml b/configs/dataset/mango_ball.yaml
new file mode 100644
index 0000000..9978372
--- /dev/null
+++ b/configs/dataset/mango_ball.yaml
@@ -0,0 +1,7 @@
+scenedir: nerf_synthetic/mango_ball
+dataset_name: blender
+downsample_train: 1
+downsample_test: 1
+ndc_ray: false
+near_far: [1, 6]
+
diff --git a/configs/dataset/mats_eevee.yaml b/configs/dataset/mats_eevee.yaml
new file mode 100644
index 0000000..3124777
--- /dev/null
+++ b/configs/dataset/mats_eevee.yaml
@@ -0,0 +1,6 @@
+scenedir: nerf_synthetic/materials_eevee
+dataset_name: blender
+downsample_train: 1
+downsample_test: 1
+ndc_ray: false
+near_far: [1, 6]
diff --git a/configs/dataset/teapot.yaml b/configs/dataset/teapot.yaml
new file mode 100644
index 0000000..76787d5
--- /dev/null
+++ b/configs/dataset/teapot.yaml
@@ -0,0 +1,7 @@
+scenedir: nerf_synthetic/teapot
+dataset_name: blender
+downsample_train: 1
+downsample_test: 1
+ndc_ray: false
+near_far: [1, 6]
+
diff --git a/configs/dataset/toaster.yaml b/configs/dataset/toaster.yaml
new file mode 100644
index 0000000..f926683
--- /dev/null
+++ b/configs/dataset/toaster.yaml
@@ -0,0 +1,7 @@
+scenedir: nerf_synthetic/toaster
+dataset_name: blender
+downsample_train: 1
+downsample_test: 1
+ndc_ray: false
+near_far: [1, 6]
+
diff --git a/configs/default.yaml b/configs/default.yaml
index 5bdf3f7..8f3934a 100644
--- a/configs/default.yaml
+++ b/configs/default.yaml
@@ -31,3 +31,4 @@ lr_upsample_reset: 1
 fp16: false
 n_bg_iters: 1000
 save_often: false
+fixed_bg: False
diff --git a/configs/field/tensorf_og.yaml b/configs/field/tensorf_og.yaml
new file mode 100644
index 0000000..76fb476
--- /dev/null
+++ b/configs/field/tensorf_og.yaml
@@ -0,0 +1,38 @@
+_partial_: True
+_target_: fields.tensoRF.TensorVMSplit
+distance_scale: 25
+density_n_comp: 16
+# density_n_comp: 24
+appearance_n_comp: 48
+app_dim: 27
+step_ratio: 0.5
+density_res_multi: 1
+contract_space: False
+smoothing: 0.5
+activation: 'softplus_shift'
+# activation: 'softplus'
+# activation: 'relu_shift'
+init_mode: rand
+interp_mode: bilinear
+# init_mode: trig
+density_shift: -10
+
+N_voxel_init: 2097156 # 128**3
+# N_voxel_init: 16777216 # 256**3
+# N_voxel_init: 134217728 # 512**3
+# N_voxel_init: 27000000 # 300**3
+N_voxel_final: 27000000 # 300**3
+# N_voxel_final: 134217728 # 512**3
+# N_voxel_final: 1073741824 # 512**3
+# upsamp_list: [2000,3000,4000,5500,7000]
+# upsamp_list: [4000,5500,7000,8000,9000]
+# upsamp_list: [4000,5500,7000,8000,9000]
+# upsamp_list: [7000,8000,9000]
+# upsamp_list: [14000,16000,18000]
+upsamp_list: [2000,3000,4000,5500,7000]
+# upsamp_list: [4000,4000,5500,7000]
+# upsamp_list: [] # 4000,4000,5500,7000]
+lr: 2e-2
+lr_net: 1e-3
+num_pretrain: 0
+
diff --git a/configs/model/tensorf.yaml b/configs/model/tensorf.yaml
index 98710a8..9b4d966 100644
--- a/configs/model/tensorf.yaml
+++ b/configs/model/tensorf.yaml
@@ -1,40 +1,77 @@
-_target_: models.tensor_nerf.TensorNeRF
-_partial_: True
-
-density_shift: -10
-alphaMask_thres: 0.001
-distance_scale: 25
-rayMarch_weight_thres: 0.0001
-nEnvSamples: 0
-fea2denseAct: 'softplus_shift'
-# fea2denseAct: 'softplus'
-# fea2denseAct: 'relu_shift'
-max_recurs: 0
-enable_refraction: True
-infinity_border: False
-enable_alpha_mask: false
-
-rf:
+arch:
+  _target_: models.tensor_nerf.TensorNeRF
   _partial_: True
-  _target_: fields.tensoRF.TensorVMSplit
-  density_n_comp: 16
-  # appearance_n_comp: 48
-  # app_dim: 48
-  appearance_n_comp: 24
-  app_dim: 27
-  step_ratio: 0.5
-  density_res_multi: 1
-  contract_space: False
-  # num_levels: 1
-  hier_sizes: [1]
-
-diffuse_module:
-  _partial_: True
-  _target_: models.render_modules.MLPDiffuse
-  pospe: 0
-  feape: 2
-  view_encoder:
-    _target_: models.ish.FullISH
-    max_degree: 4
-  featureC: 128
-  num_layers: 5
+
+  alphaMask_thres: 0.0001
+  rayMarch_weight_thres: 0.0001
+  attach_normal_iter: 000
+  nEnvSamples: 0
+  appdim_noise_std: 0
+  max_recurs: 0
+  infinity_border: False
+  back_clip: 0.3
+
+  tonemap:
+    # _target_: models.tonemap.HDRTonemap
+    _target_: models.tonemap.LinearTonemap
+    # _target_: models.tonemap.SRGBTonemap
+
+  sampler:
+    _target_: samplers.continuous_alphagrid.ContinuousAlphagrid
+    _partial_: True
+    multiplier: 1
+    shrink_iters: [2000, 4000]
+    dynamic_batchsize: False
+    sample_mode: single_jitter
+    test_sample_mode: midpoint
+    threshold: 1e-3
+    grid_size: 128
+    bound: 1.5
+
+  diffuse_module:
+    _partial_: True
+    _target_: models.render_modules.MLPDiffuse
+    # _target_: models.render_modules.MLPRender
+    pospe: -1
+    feape: 2
+    view_encoder:
+      _target_: models.render_modules.PE
+      max_degree: 2
+    featureC: 128
+    num_layers: 3
+    lr: 1e-3
+
+  normal_module:
+    _partial_: True
+    _target_: models.render_modules.MLPNormal
+    lr: 1e-3
+    pospe: -1
+    feape: 2
+    # pospe: 12
+    # feape: 0
+    featureC: 128
+    num_layers: 3
+    # allocation: 3
+
+  rf: 'placeholder'
+
+params:
+  L1_weight_inital: 8e-5
+  L1_weight_rest: 4e-5
+
+  TV_weight_density: 0.0
+  TV_weight_app: 0.0
+  normal_lambda: 3e-3
+  diffuse_lambda: 0
+  backwards_rays_lambda: 0.1
+  floater_lambda: 0 #1e-4
+  visibility_lambda: 0
+  N_visibility_rays: 128
+  # floater_lambda: 0.00001
+  ortho_weight: 0
+
+  n_iters: 30000
+  charbonier_loss: false
+  start_density: 1e-4
+  lr_init: 0.02
+  batch_size: 4096
diff --git a/dataLoader/blender.py b/dataLoader/blender.py
index 63a72ad..145a587 100644
--- a/dataLoader/blender.py
+++ b/dataLoader/blender.py
@@ -92,6 +92,7 @@ class BlenderDataset(Dataset):
         self.image_paths = []
         self.poses = []
         self.all_rays = []
+        self.all_norms = []
         self.all_rgbs = []
         self.all_masks = []
         self.all_depth = []
@@ -136,11 +137,14 @@ class BlenderDataset(Dataset):
             # img = img.clip(0, 1)
             self.all_rgbs += [img]
 
+            # self.all_norms += [self.get_normal(i).reshape(-1, 3)]
+
 
             self.all_rays += [rays]  # (h*w, 6)
 
 
         self.poses = torch.stack(self.poses)
+        # self.all_norms = torch.cat(self.all_norms)
         if not self.is_stack:
             self.all_rays = torch.cat(self.all_rays, 0)  # (len(self.meta['frames])*h*w, 3)
             self.all_rgbs = torch.cat(self.all_rgbs, 0)  # (len(self.meta['frames])*h*w, 3)
diff --git a/fields/tensor_base.py b/fields/tensor_base.py
index 39d8b80..6407da8 100644
--- a/fields/tensor_base.py
+++ b/fields/tensor_base.py
@@ -7,7 +7,6 @@ import utils
 class TensorBase(torch.nn.Module):
     def __init__(self, aabb, density_shift, activation, lr, lr_net, contract_space=False, distance_scale=25, num_pretrain=0):
         super().__init__()
-        self.register_buffer('aabb', aabb)
         self.lr = lr
         self.lr_net = lr_net
         self.activation = activation
@@ -15,7 +14,11 @@ class TensorBase(torch.nn.Module):
         self.density_shift = density_shift
         self.contract_space = contract_space
         self.distance_scale = distance_scale
-        self.set_register('aabbSize', self.aabb[1] - self.aabb[0])
+        self.set_aabb(aabb)
+
+    def set_aabb(self, aabb):
+        self.set_register('aabb', aabb)
+        self.set_register('aabbSize', aabb[1] - aabb[0])
         self.set_register('invaabbSize', 2.0/self.aabbSize)
         self.set_register('aabbDiag', torch.sqrt(torch.sum(torch.square(self.aabbSize))))
 
@@ -95,8 +98,8 @@ class TensorVoxelBase(TensorBase):
     def update_stepSize(self, grid_size):
         grid_size = torch.LongTensor(grid_size)
         print("grid size", grid_size)
-        print("density grid size", [int(self.density_res_multi*g) for g in grid_size])
         print("aabb", self.aabb.view(-1))
+
         self.set_register('grid_size', grid_size)
         self.set_register('units', self.aabbSize.to(self.grid_size.device) / (self.grid_size-1))
         # min is more accurate than mean
diff --git a/models/ish.py b/models/ish.py
index d08c8eb..4af6df2 100644
--- a/models/ish.py
+++ b/models/ish.py
@@ -112,6 +112,18 @@ class FullISH(torch.nn.Module):
     def dim(self):
         return (self.max_degree+1)**2
 
+    def forward(self, vecs, roughness):
+        base = eval_sh_bases(self.max_degree, vecs)
+        return base
+
+class FullISHScaled(torch.nn.Module):
+    def __init__(self, max_degree=1):
+        super().__init__()
+        self.max_degree = max_degree
+
+    def dim(self):
+        return (self.max_degree+1)**2
+
     def forward(self, vecs, roughness):
         kappa = 1/(roughness+1e-8)
         base = eval_sh_bases_scaled(self.max_degree, vecs, kappa)
diff --git a/models/safemath.py b/models/safemath.py
index fe82b6c..1eabbab 100644
--- a/models/safemath.py
+++ b/models/safemath.py
@@ -68,7 +68,7 @@ def integrated_pos_enc(x_coord, min_deg, max_deg, diag=True):
   if diag:
     x, x_cov_diag = x_coord
     device = x.device
-    scales = torch.tensor([2**i for i in range(min_deg, max_deg)], device=device)
+    scales = torch.tensor([2**(i-1) for i in range(min_deg, max_deg)], device=device)
     shape = list(x.shape[:-1]) + [-1]
     y = torch.reshape(x[..., None, :] * scales[:, None], shape)
     y_var = torch.reshape(x_cov_diag[..., None, :] * scales[:, None]**2, shape)
diff --git a/modules/naive_vis_cache.py b/modules/naive_vis_cache.py
index eb08491..1674f5d 100644
--- a/modules/naive_vis_cache.py
+++ b/modules/naive_vis_cache.py
@@ -1,6 +1,9 @@
 import torch
 from mutils import morton3D, normalize
 from icecream import ic
+import imageio
+from pathlib import Path
+import numpy as np
 
 class NaiveVisCache(torch.nn.Module):
     def __init__(self, grid_size, bound, **kwargs):
@@ -8,7 +11,7 @@ class NaiveVisCache(torch.nn.Module):
         self.grid_size = grid_size
         self.bound = bound
         self.midpoint = 128
-        self.jump = 8
+        self.jump = 1
         cache = (self.midpoint) * torch.ones((self.grid_size, self.grid_size, self.grid_size, 6), dtype=torch.uint8)
         self.register_buffer('cache', cache)
 
@@ -43,9 +46,16 @@ class NaiveVisCache(torch.nn.Module):
         return coords[..., 0], coords[..., 1], coords[..., 2], face_index
 
     @torch.no_grad()
-    def mask(self, norm_ray_origins, viewdirs, world_bounces, *args, **kwargs):
+    def mask(self, norm_ray_origins, viewdirs, world_bounces, full_bounce_mask, ray_mask, weight, *args, **kwargs):
         i, j, k, face_index = self.rays2inds(norm_ray_origins, -viewdirs)
         vals = self.cache[i, j, k, face_index]
+        mask = torch.zeros_like(full_bounce_mask)
+        mask[range(mask.shape[0]), weight.max(dim=1).indices] = True
+        max_weight_mask = mask[full_bounce_mask].reshape(-1, 1).expand(*ray_mask.shape)[ray_mask]
+        vals[~max_weight_mask] = 255
+
+        # select a maximum of one point along each ray to allow for world bounces
+        
         # eps = 2e-2
         # vis_mask = ((norm_ray_origins[..., 0] < eps) & (norm_ray_origins[..., 1] > -eps))
         inds = vals.argsort()[:world_bounces]
@@ -53,10 +63,12 @@ class NaiveVisCache(torch.nn.Module):
         # mask = torch.zeros_like(vals, dtype=torch.bool)
         # mask[inds] = True
         # vals is high when it reaches BG and low when it does not
+        # ic(vals.min(), vals.float().mean())
         mask1 = vals < self.midpoint
         mask2 = torch.zeros_like(mask1)
         mask2[inds] = True
         mask = mask1 & mask2
+        # mask = mask1 & max_weight_mask
         # ic((vis_mask | mask).sum(), (vis_mask & mask).sum())
         # ic((vis_mask).sum(), (mask).sum())
         return mask
@@ -68,17 +80,49 @@ class NaiveVisCache(torch.nn.Module):
         return vals > self.midpoint
 
     @torch.no_grad()
-    def update(self, norm_ray_origins, viewdirs, app_features, termination, bgvisibility):
-        # visibility is a bool
-        # bgvisibility is true if the bg is visible
+    def ray_update(self, viewdirs, xyz_normed, app_mask, ray_valid):
+        # xyz_sampled: (M, 4) float. premasked valid sample points
+        # viewdirs: (M, 3) float. premasked corresponding viewdirs
+        # max_samps = N
+        # z_vals: (b, N) float. distance along ray to sample
+        # ray_valid: (b, N) bool. mask of which samples are valid
+        # app_mask: [b, N]
+
+        # convert app_mask into bgvisibility
+        # this can be done by computing the termination for each ray, then calculating the distance to each point along the ray
+        inds = torch.arange(app_mask.shape[1], device=viewdirs.device)
+        term_ind = (app_mask * inds.reshape(1, -1)).min(dim=1, keepdim=True).values
+        bgvisibility = (inds < term_ind)[ray_valid]
+        self.update(xyz_normed[..., :3], -viewdirs, bgvisibility)
+
+    def render(self):
+        N = self.cache.shape[-1]
+        ims = []
+        for direction in range(N):
+            volume = self.cache[..., direction].float()
+            im1 = volume.mean(dim=0)
+            im2 = volume.mean(dim=1)
+            im3 = volume.mean(dim=2)
+            ims.append(torch.cat([im1, im2, im3], dim=0).cpu())
+        im = torch.cat(ims, dim=1)
+        return im
+
+    def save(self, path, prefix=''):
+        im = self.render()
+        im = im.cpu().numpy().astype(np.uint8)
+        imageio.imwrite(str(Path(path) / f'{prefix}_viscache.png'), im)
+
+    @torch.no_grad()
+    def update(self, norm_ray_origins, viewdirs, bgvisibility):
+        # visibility is a bool bgvisibility is true if the bg is visible
         # output mask is true if bg is not visible
         i, j, k, face_index = self.rays2inds(norm_ray_origins, viewdirs)
-        eps = 2e-2
+        eps = 5e-3
         vals = self.cache[i, j, k, face_index].int() + torch.where(bgvisibility, 1, -self.jump)
-        # vals = self.cache[i, j, k, face_index].int() + torch.where(~vis_mask, 0, -self.jump)
+        vis_mask = ((norm_ray_origins[..., 0] < eps) & (norm_ray_origins[..., 1] > -eps)) & (norm_ray_origins.abs().min(dim=1).values < eps)
+        # vals = self.cache[i, j, k, face_index].int() + torch.where(~vis_mask, 1, -self.jump)
         # vals = self.cache[indices, face_index].int() + torch.where(bgvisibility, self.jump, -self.jump)
 
         # ic((vis_mask | bgvisibility).sum(), (vis_mask & bgvisibility).sum())
         # ic((vis_mask).sum(), (bgvisibility).sum())
         self.cache[i, j, k, face_index] = vals.clamp(0, 255).type(torch.uint8)
-        return torch.tensor(0.0, device=norm_ray_origins.device)
diff --git a/requirements.txt b/requirements.txt
index 2e55b0f..307adfe 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -16,3 +16,5 @@ imageio-ffmpeg
 hydra-core
 icecream
 warp-lang
+loguru
+git+https://github.com/NVlabs/nvdiffrast
diff --git a/samplers/continuous_alphagrid.py b/samplers/continuous_alphagrid.py
index 7a78862..913149e 100644
--- a/samplers/continuous_alphagrid.py
+++ b/samplers/continuous_alphagrid.py
@@ -2,7 +2,6 @@ import torch
 import math
 import raymarching_full as raymarching 
 import torch.nn.functional as F
-from numba import jit
 import numpy as np
 from icecream import ic
 import time
@@ -72,13 +71,16 @@ class ContinuousAlphagrid(torch.nn.Module):
                  aabb=None,
                  near_far=[0.2, 6],
                  threshold=0.002,
+                 shrink_threshold=None,
                  multiplier=1, 
                  sample_mode='multi_jitter',
                  test_sample_mode=None,
                  update_freq=16,
+                 disable_cascade=True,
                  max_samples=int(1.1e6),
                  dynamic_batchsize=False,
-                 shrink_freq=1000,
+                 conv=7,
+                 shrink_iters=[],
                  grid_size=128):
         super().__init__()
 
@@ -90,12 +92,17 @@ class ContinuousAlphagrid(torch.nn.Module):
         # distance of the candidate from the center. The resolution decreases by a factor of 2 for
         # each cascade.
 
+        self.conv = conv
+        self.shrink_threshold = shrink_threshold
         self.bound = bound if aabb is None else aabb.abs().max()
+        self.aabb = None
         self.dynamic_batchsize = dynamic_batchsize
         self.update_freq = update_freq
         self.cascade = int(1 + math.ceil(math.log2(bound)))# - 1
         # TODO REMOVE: The higher cascades aren't working
-        self.cascade = 1
+        self.disable_cascade = disable_cascade
+        if self.disable_cascade:
+            self.cascade = 1
         ic(self.cascade, self.bound)
         self.grid_size = grid_size
         self.multiplier = int(multiplier)
@@ -106,7 +113,7 @@ class ContinuousAlphagrid(torch.nn.Module):
         self.active_density_thresh = threshold
         self.max_samples = max_samples 
         self.stepsize = 0.003383
-        self.shrink_freq = shrink_freq
+        self.shrink_iters = shrink_iters
 
         self.sample_mode = sample_mode
         self.test_sample_mode = sample_mode if test_sample_mode is None else test_sample_mode
@@ -241,20 +248,17 @@ class ContinuousAlphagrid(torch.nn.Module):
         device = rays_chunk.device
         N, M = xyz_sampled.shape[:2]
         # sample alphas and cull samples from the ray
-        # alpha_mask = self.alphaMask.sample_alpha(
-        #     xyz_sampled[ray_valid], contract_space=self.contract_space)
-        coords, cas = self.xyz2coords(xyz_sampled[ray_valid][..., :3])
-        # indices = raymarching.morton3D(coords).long() # [N]
-        indices = morton3D(coords).long() # [N]
-        indices = indices.clip(min=0, max=self.density_bitfield.shape[0]*8) # [N]
-        alpha = self.density_grid[cas, indices]
-        alpha_mask = alpha > self.active_density_thresh
-
-        alpha_mask = (self.density_bitfield[indices // 8] & (1 << (indices % 8))) > 0
-
-        ray_invalid = ~ray_valid
-        ray_invalid[ray_valid] |= (~alpha_mask)
-        ray_valid = ~ray_invalid
+        # coords, cas = self.xyz2coords(xyz_sampled[ray_valid][..., :3])
+        # indices = morton3D(coords).long() # [N]
+        # indices = indices.clip(min=0, max=self.density_bitfield.shape[0]*8) # [N]
+        # alpha = self.density_grid[cas, indices]
+        # alpha_mask = alpha > self.active_density_thresh
+        #
+        # alpha_mask = (self.density_bitfield[indices // 8] & (1 << (indices % 8))) > 0
+        #
+        # ray_invalid = ~ray_valid
+        # ray_invalid[ray_valid] |= (~alpha_mask)
+        # ray_valid = ~ray_invalid
 
         dists = torch.cat((z_vals[:, 1:] - z_vals[:, :-1], torch.zeros_like(z_vals[:, :1])), dim=-1)
 
@@ -292,23 +296,27 @@ class ContinuousAlphagrid(torch.nn.Module):
         cas = self.xyz2cas(xyz)
         cas_xyzs = xyz
         bound = (2 ** cas).clip(max=self.bound)
+        if self.disable_cascade:
+            bound = self.bound
         half_grid_size = bound / self.grid_size
 
         o_xyzs = (cas_xyzs / (bound - half_grid_size)[..., None]).clip(min=-1, max=1)
         coords = (o_xyzs+1) / 2 * (self.grid_size - 1)
         return coords.long(), cas
 
-    def coords2xyz(self, coords, cas, randomize=True):
+    def coords2xyz(self, coords, cas, randomize=True, conv=1):
         xyzs = 2 * coords.float() / (self.grid_size - 1) - 1 # [N, 3] in [-1, 1]
 
         # cascading
         bound = min(2 ** cas, self.bound)
+        if self.disable_cascade:
+            bound = self.bound
         half_grid_size = bound / self.grid_size
         # scale to current cascade's resolution
         cas_xyzs = xyzs * (bound - half_grid_size)
         # add noise in [-hgs, hgs]
         if randomize:
-            cas_xyzs += (torch.rand_like(cas_xyzs) * 2 - 1) * half_grid_size
+            cas_xyzs += (torch.randn_like(cas_xyzs)) * half_grid_size * conv / 2
         return cas_xyzs
 
     @torch.no_grad()
@@ -382,15 +390,15 @@ class ContinuousAlphagrid(torch.nn.Module):
     def check_schedule(self, iteration, rf):
         if iteration % self.update_freq == 0:
             self.update(rf)
-        if self.shrink_freq > 0 and iteration >= self.shrink_freq and iteration % self.shrink_freq == 0:
+        if iteration in self.shrink_iters:
             new_aabb = self.get_bounds()
-            rf.shrink(new_aabb)
-            self.update(rf, init=True)
+            rf.shrink(new_aabb, self.grid_size)
+            # self.update(rf, init=True)
         return False
 
     def update(self, rf, decay=0.95, S=128, init=False):
-        self.aabb = rf.aabb
-        self.units = rf.units
+        # TODO REMOVE
+        self.aabb = rf.aabb# if self.aabb is None else self.aabb
         self.contract_space = rf.contract_space
         # reso_mask = reso_cur
         self.update_density(rf, decay, S=S)
@@ -402,8 +410,9 @@ class ContinuousAlphagrid(torch.nn.Module):
 
     def get_bounds(self):
         xyzs = []
+        thresh = self.active_density_thresh if self.shrink_threshold is None else self.shrink_threshold
         for cas in range(self.cascade):
-            active_grid = self.density_grid[cas] > self.active_density_thresh
+            active_grid = self.density_grid[cas] > thresh
             occ_indices = torch.nonzero(active_grid).squeeze(-1) # [Nz]
             occ_coords = morton3D_invert(occ_indices) # [N, 3]
             # convert coords to aabb
@@ -414,7 +423,7 @@ class ContinuousAlphagrid(torch.nn.Module):
             xyzs.min(dim=0).values,
             xyzs.max(dim=0).values,
         ])
-        ic(aabb)
+        # aabb = torch.tensor([[-0.6732, -1.1929, -0.4606], [0.6732,  1.1929,  1.0512]], device=xyzs.device)
         return aabb
 
     def sample_occupied(self, cas, N):
@@ -454,7 +463,7 @@ class ContinuousAlphagrid(torch.nn.Module):
 
                         # cascading
                         for cas in range(self.cascade):
-                            cas_xyzs = self.coords2xyz(coords, cas)
+                            cas_xyzs = self.coords2xyz(coords, cas, conv=self.conv)
                             # query density
                             cas_norm = rf.normalize_coord(cas_xyzs)
                             sigmas = rf.compute_densityfeature(cas_norm).reshape(-1)
@@ -481,7 +490,7 @@ class ContinuousAlphagrid(torch.nn.Module):
                 indices = torch.cat([indices, occ_indices], dim=0)
                 coords = torch.cat([coords, occ_coords], dim=0)
                 # same below
-                cas_xyzs = self.coords2xyz(coords, cas)
+                cas_xyzs = self.coords2xyz(coords, cas, conv=self.conv)
                 # query density
                 cas_norm = rf.normalize_coord(cas_xyzs)
                 sigmas = rf.compute_densityfeature(cas_norm).reshape(-1)
