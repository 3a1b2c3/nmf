{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dronelab/normalrf\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import imageio\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"] = \"1\"\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import yaml\n",
    "import lpips\n",
    "import scipy.signal\n",
    "\n",
    "import sys\n",
    "base_path = Path(os.path.abspath('')).parent\n",
    "print(base_path)\n",
    "sys.path.append(str(base_path))\n",
    "import torch\n",
    "from dataLoader import dataset_dict\n",
    "\n",
    "def disp_im(im):\n",
    "    plt.close()\n",
    "    plt.cla()\n",
    "    fig = plt.imshow(im)\n",
    "    plt.close()\n",
    "    display(fig.figure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dronelab/miniconda3/envs/31/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dronelab/miniconda3/envs/31/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/dronelab/miniconda3/envs/31/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    }
   ],
   "source": [
    "def rgb_ssim(img0, img1, max_val,\n",
    "             filter_size=11,\n",
    "             filter_sigma=1.5,\n",
    "             k1=0.01,\n",
    "             k2=0.03,\n",
    "             return_map=False):\n",
    "    # Modified from https://github.com/google/mipnerf/blob/16e73dfdb52044dcceb47cda5243a686391a6e0f/internal/math.py#L58\n",
    "    assert len(img0.shape) == 3\n",
    "    assert img0.shape[-1] == 3\n",
    "    assert img0.shape == img1.shape\n",
    "\n",
    "    # Construct a 1D Gaussian blur filter.\n",
    "    hw = filter_size // 2\n",
    "    shift = (2 * hw - filter_size + 1) / 2\n",
    "    f_i = ((np.arange(filter_size) - hw + shift) / filter_sigma)**2\n",
    "    filt = np.exp(-0.5 * f_i)\n",
    "    filt /= np.sum(filt)\n",
    "\n",
    "    # Blur in x and y (faster than the 2D convolution).\n",
    "    def convolve2d(z, f):\n",
    "        return scipy.signal.convolve2d(z, f, mode='valid')\n",
    "\n",
    "    filt_fn = lambda z: np.stack([\n",
    "        convolve2d(convolve2d(z[...,i], filt[:, None]), filt[None, :])\n",
    "        for i in range(z.shape[-1])], -1)\n",
    "    mu0 = filt_fn(img0)\n",
    "    mu1 = filt_fn(img1)\n",
    "    mu00 = mu0 * mu0\n",
    "    mu11 = mu1 * mu1\n",
    "    mu01 = mu0 * mu1\n",
    "    sigma00 = filt_fn(img0**2) - mu00\n",
    "    sigma11 = filt_fn(img1**2) - mu11\n",
    "    sigma01 = filt_fn(img0 * img1) - mu01\n",
    "\n",
    "    # Clip the variances and covariances to valid values.\n",
    "    # Variance must be non-negative:\n",
    "    sigma00 = np.maximum(0., sigma00)\n",
    "    sigma11 = np.maximum(0., sigma11)\n",
    "    sigma01 = np.sign(sigma01) * np.minimum(\n",
    "        np.sqrt(sigma00 * sigma11), np.abs(sigma01))\n",
    "    c1 = (k1 * max_val)**2\n",
    "    c2 = (k2 * max_val)**2\n",
    "    numer = (2 * mu01 + c1) * (2 * sigma01 + c2)\n",
    "    denom = (mu00 + mu11 + c1) * (sigma00 + sigma11 + c2)\n",
    "    ssim_map = numer / denom\n",
    "    ssim = np.mean(ssim_map)\n",
    "    return ssim_map if return_map else ssim\n",
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "loss_fn_alex = lpips.LPIPS(net='alex').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(p):\n",
    "    stats_files = ['stats_augnle.yaml', 'stats_augnl.yaml', 'stats_augn.yaml', 'stats_aug.yaml', 'stats.yaml']\n",
    "    stat_file = [s for s in stats_files if (p / \"imgs_test_all\" / s).exists()]\n",
    "    stat_file = stat_file[0] if len(stat_file) else None\n",
    "    if stat_file is None:\n",
    "        return None\n",
    "    data_path = p / \"imgs_test_all\" / stat_file\n",
    "    with data_path.open('r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dronelab/miniconda3/envs/31/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642969563/work/aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log/noupsample/hotdog_v38_noupsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data test (200): 100%|██████████| 200/200 [00:05<00:00, 36.60it/s]\n",
      "/tmp/ipykernel_4928/819918741.py:31: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning dissapear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  pred_im = torch.as_tensor(imageio.imread(p / \"imgs_test_all\" / f\"{idx:03d}.png\")).float() / 255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log/noupsample/ball_v38_noupsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data test (200): 100%|██████████| 200/200 [00:05<00:00, 35.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log/noupsample/materials_v38_noupsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data test (200): 100%|██████████| 200/200 [00:05<00:00, 35.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log/noupsample/mic_v38_noupsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data test (200): 100%|██████████| 200/200 [00:04<00:00, 44.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log/noupsample/drums_v38_noupsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data test (200): 100%|██████████| 200/200 [00:05<00:00, 37.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log/noupsample/ficus_v38_noupsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data test (200): 100%|██████████| 200/200 [00:04<00:00, 40.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log/noupsample/lego_v38_noupsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data test (200): 100%|██████████| 200/200 [00:05<00:00, 35.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log/noupsample/ship_v38_noupsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data test (200): 100%|██████████| 200/200 [00:05<00:00, 37.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log/noupsample/car_v38_noupsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data test (200): 100%|██████████| 200/200 [00:05<00:00, 37.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log/noupsample/toaster_v38_noupsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data test (200): 100%|██████████| 200/200 [00:05<00:00, 35.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log/noupsample/coffee_v38_noupsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data test (200): 100%|██████████| 200/200 [00:05<00:00, 37.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log/noupsample/helmet_v38_noupsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data test (200): 100%|██████████| 200/200 [00:05<00:00, 39.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log/noupsample/chair_v38_noupsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data test (200): 100%|██████████| 200/200 [00:05<00:00, 39.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../log/noupsample/teapot_v38_noupsample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data test (200): 100%|██████████| 200/200 [00:04<00:00, 44.63it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# log_dir = Path(\"../log\") / \"tensorf\"\n",
    "# log_dir = Path(\"../log\") / \"fixedmip128\"\n",
    "# log_dir = Path(\"../log\") / \"singlebounce_samen\"\n",
    "# exps = [\"noprednorms_nl0_conserve_pb0\", 'fixedmip128', 'tensorf', 'singlebounce_samen']\n",
    "# exps = ['interpdiffuse', 'interpdiffuse_flipnorm']\n",
    "exps = ['noupsample']\n",
    "\n",
    "stats_files = ['stats_augn.yaml', 'stats_aug.yaml', 'stats.yaml']\n",
    "datadir = \"/optane/nerf_datasets\"\n",
    "for exp in exps:\n",
    "    log_dir = Path(\"../log\") / exp\n",
    "    for p in log_dir.glob(\"*\"):\n",
    "        print(p)\n",
    "        pano_path = p / \"imgs_test_all\" / \"envmaps\" / \"pano.exr\"\n",
    "        mapped_pano_path = p / \"imgs_test_all\" / \"envmaps\" / \"mapped_pano.png\"\n",
    "        new_data_path = p / \"imgs_test_all\" / \"stats_augnl.yaml\"\n",
    "\n",
    "        old_data = get_stats(p)\n",
    "\n",
    "        config = OmegaConf.load(p / 'config.yaml')\n",
    "        dname = Path(config['dataset']['scenedir']).name\n",
    "\n",
    "        white_bg = config.dataset.white_bg if hasattr(config.dataset, 'white_bg') else True\n",
    "        dataset = dataset_dict[config.dataset.dataset_name]\n",
    "        test_dataset = dataset(os.path.join(datadir, config.dataset.scenedir), split='test',\n",
    "                            downsample=config.dataset.downsample_train, is_stack=True, white_bg=white_bg, is_testing=True)\n",
    "        lpips_vs = []\n",
    "        ssims = []\n",
    "        psnrs = []\n",
    "        for idx in range(len(test_dataset)):\n",
    "            pred_im = torch.as_tensor(imageio.imread(p / \"imgs_test_all\" / f\"{idx:03d}.png\")).float() / 255\n",
    "            gt_im = test_dataset.all_rgbs[idx]\n",
    "\n",
    "            pred_t = pred_im.permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "            gt_t = gt_im.permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "            err = (pred_im - gt_im)**2\n",
    "            psnr = -10 * torch.log(torch.mean(err)) / np.log(10.0)\n",
    "            psnrs.append(psnr)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                lpips_v = loss_fn_alex(pred_t, gt_t, normalize=True).cpu()\n",
    "            ssims.append(rgb_ssim(pred_im, gt_im, 1))\n",
    "            lpips_vs.append(float(lpips_v))\n",
    "\n",
    "        with new_data_path.open('w') as f:\n",
    "            old_data['l_alex'] = float(sum(lpips_vs) / len(lpips_vs)) if len(lpips_vs) > 0 else 0\n",
    "            old_data['new_psnr'] = float(sum(psnrs) / len(psnrs)) if len(psnrs) > 0 else 0\n",
    "            old_data['ssim'] = float(sum(ssims) / len(ssims)) if len(ssims) > 0 else 0\n",
    "            yaml.dump(old_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "31",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "028f34ffe305a9c9d9afad2118f6894d15876b6d4b2e233b2f3e6907c2ac8580"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
